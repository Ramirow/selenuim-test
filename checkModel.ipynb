{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "checkModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramirow/selenuim-test/blob/master/checkModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ0R6202Epxv",
        "colab_type": "code",
        "outputId": "6208e432-0e20-479c-9891-ac540f6a0028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#!pip uninstall tensorflow-gpu\n",
        "#!pip install tensorflow-gpu==1.15\n",
        "!pip install --upgrade keras\n",
        "#!python -c 'import keras; print(keras.__version__)'"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DDB8z9QgqYk",
        "colab_type": "code",
        "outputId": "3bb0fe1d-2679-4c13-ce89-6ea101d2e99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#clone the data set\n",
        "!git clone https://github.com/Ramirow/Machine-Learning-DataSet.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Machine-Learning-DataSet'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects:   8% (1/12)\u001b[K\rremote: Counting objects:  16% (2/12)\u001b[K\rremote: Counting objects:  25% (3/12)\u001b[K\rremote: Counting objects:  33% (4/12)\u001b[K\rremote: Counting objects:  41% (5/12)\u001b[K\rremote: Counting objects:  50% (6/12)\u001b[K\rremote: Counting objects:  58% (7/12)\u001b[K\rremote: Counting objects:  66% (8/12)\u001b[K\rremote: Counting objects:  75% (9/12)\u001b[K\rremote: Counting objects:  83% (10/12)\u001b[K\rremote: Counting objects:  91% (11/12)\u001b[K\rremote: Counting objects: 100% (12/12)\u001b[K\rremote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 12 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (12/12), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am9Fip3vFeKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Lambda\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuNcOa_X5p6_",
        "colab_type": "code",
        "outputId": "bb8f499b-32f5-45ba-8c2f-c07cea16758a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!brew install wget\n",
        "\n",
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: brew: command not found\n",
            "--2019-12-17 08:28:18--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.47.38\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.47.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-nOkigGFeKi",
        "colab_type": "code",
        "outputId": "6cac4b32-08ef-4f2a-eed5-26e833635fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim import models\n",
        "word2vec = models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smYlzl-KFeKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File paths\n",
        "FIRST_TXT = '/content/Machine-Learning-DataSet/TRAIN1.txt'\n",
        "SECOND_TXT = '/content/Machine-Learning-DataSet/TEST.txt'\n",
        "THIRD_TXT = '/content/Machine-Learning-DataSet/TRAIN2.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smN_Ab0PFeKn",
        "colab_type": "code",
        "outputId": "12838c95-1d28-4605-e04b-04b6f40fb42f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "help = []\n",
        "req = []\n",
        "test = []\n",
        "sim = []\n",
        "scenario = False\n",
        "te = True\n",
        "#writing from file one to file two \n",
        "c = 0 \n",
        "with open(FIRST_TXT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "for line in lines:\n",
        "            #print('\\n',\"WHen THEN \",line)\n",
        "            if(\"Scenario\" not in line[:20] and scenario):\n",
        "                 help.append(line) \n",
        "                 te = True   \n",
        "            elif  \"Scenario\" in  line[:20] and te:\n",
        "                 #print(\"Help \",help)\n",
        "                 test.append(''.join(help))\n",
        "                 #print('\\n',\"Scenario \",line)\n",
        "                 req.append(line)\n",
        "                 scenario = True\n",
        "                 help = []\n",
        "                 sim.append(\"1\")\n",
        "                 te = False   \n",
        "for i in range(3500):\n",
        "    s1 = random.choice(req)\n",
        "    s2 = random.choice(test)\n",
        "    ind1 = req.index(s1)\n",
        "    ind2 = test.index(s2)\n",
        "    if ind1 != ind2:\n",
        "        req.append(s1)\n",
        "        test.append(s2)\n",
        "        sim.append(\"0\")\n",
        "\n",
        "'''\n",
        "# Optional : trying to add data from another repository\n",
        "with open(THIRD_TXT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "for line in lines:\n",
        "            #print('\\n',\"WHen THEN \",line)\n",
        "            if(\"Scenario\" not in line[:20] and scenario):\n",
        "                 help.append(line) \n",
        "                 te = True   \n",
        "            elif  \"Scenario\" in  line[:20] and te:\n",
        "                 #print(\"Help \",help)\n",
        "                 test.append(''.join(help))\n",
        "                 #print('\\n',\"Scenario \",line)\n",
        "                 req.append(line)\n",
        "                 scenario = True\n",
        "                 sim.append(\"1\")\n",
        "                 te = False  \n",
        "                         \n",
        "# the end of optional adding         \n",
        "'''        \n",
        "print(\"req length\",len(req))\n",
        "print(\"test len \" , len(test))\n",
        "print(\"sim length \", len(sim))\n",
        "\n",
        "df = {'requirement':req , 'testcase': test,'similarity': sim}  \n",
        "train_df = pd.DataFrame(df) \n",
        "train_df \n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "req length 4446\n",
            "test len  4446\n",
            "sim length  4446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>requirement</th>\n",
              "      <th>testcase</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Scenario: Feature Setup\\n</td>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Scenario: Feature with a Background and Scen...</td>\n",
              "      <td>Given a new working directory\\n    And a f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Scenario: S1\\n</td>\n",
              "      <td>Given a file named \"features/background_ex...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Scenario: S2\\n</td>\n",
              "      <td>When a step passes\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scenario: S1\\n</td>\n",
              "      <td>Then a step passes\\n            An...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4441</th>\n",
              "      <td>Scenario: Alice in Antarctica\\n</td>\n",
              "      <td>Given I write text \"&lt;text&gt;\" to std...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4442</th>\n",
              "      <td>Scenario: A1\\n</td>\n",
              "      <td>Given a step passes\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4443</th>\n",
              "      <td>Scenario: One...\\n</td>\n",
              "      <td>When I run \"behave --name='-- @.* Alice' -...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4444</th>\n",
              "      <td>Scenario: Bob in Berlin\\n</td>\n",
              "      <td>When I run \"behave @unknown_feature_config...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4445</th>\n",
              "      <td>Scenario Outline: Use unknown placeholde...</td>\n",
              "      <td>When a step passes # features/step...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4446 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            requirement  ... similarity\n",
              "0                             Scenario: Feature Setup\\n  ...          1\n",
              "1       Scenario: Feature with a Background and Scen...  ...          1\n",
              "2                                        Scenario: S1\\n  ...          1\n",
              "3                                        Scenario: S2\\n  ...          1\n",
              "4                                        Scenario: S1\\n  ...          1\n",
              "...                                                 ...  ...        ...\n",
              "4441                    Scenario: Alice in Antarctica\\n  ...          0\n",
              "4442                                     Scenario: A1\\n  ...          0\n",
              "4443                                 Scenario: One...\\n  ...          0\n",
              "4444                          Scenario: Bob in Berlin\\n  ...          0\n",
              "4445        Scenario Outline: Use unknown placeholde...  ...          0\n",
              "\n",
              "[4446 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBKQ53F9FeKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8f7aca63-b459-4e81-9322-98fafc353b8e"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "req = []\n",
        "test = []\n",
        "sim = []\n",
        "scenario = False\n",
        "te = True\n",
        "#writing from file one to file two \n",
        "c = 0 \n",
        "with open(SECOND_TXT, \"r\") as f:\n",
        "    lines = f.readlines()   \n",
        "for line in lines:\n",
        "            #print('\\n',\"WHen THEN \",line)\n",
        "            if(\"Scenario\" not in line[:20] and scenario):\n",
        "                 help.append(line) \n",
        "                 te = True   \n",
        "            elif  \"Scenario\" in  line[:20] and te:\n",
        "                 #print(\"Help \",help)\n",
        "                 test.append(''.join(help))\n",
        "                 #print('\\n',\"Scenario \",line)\n",
        "                 req.append(line)\n",
        "                 scenario = True\n",
        "                 help = []\n",
        "                 sim.append(\"1\")\n",
        "                 te = False \n",
        "'''\n",
        "for i in range(30):\n",
        "    s1 = random.choice(req)\n",
        "    s2 = random.choice(test)\n",
        "    ind1 = req.index(s1)\n",
        "    ind2 = test.index(s2)\n",
        "    if ind1 != ind2:\n",
        "        req.append(s1)\n",
        "        test.append(s2)\n",
        "        sim.append(\"0\")\n",
        "'''                        \n",
        "print(\"req length\",len(req))\n",
        "print(\"test len \" , len(test))\n",
        "print(\"sim length \", len(sim))\n",
        "\n",
        "df = {'requirement':req , 'testcase': test,'similarity': sim}  \n",
        "test_df = pd.DataFrame(df) \n",
        "test_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "req length 41\n",
            "test len  41\n",
            "sim length  41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>requirement</th>\n",
              "      <th>testcase</th>\n",
              "      <th>similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Scenario: I want to validate the functiona...</td>\n",
              "      <td>Given the following user-data is p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Scenario: I want to upload examples tar ba...</td>\n",
              "      <td>When I create a new JL notebook with n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#Scenario: I want to validate the Python S...</td>\n",
              "      <td>When I upload the example tar ball fil...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Scenario: I want to validate automated pyt...</td>\n",
              "      <td># Given I will get a kernel existing in...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scenario: I want to validate SSL connectiv...</td>\n",
              "      <td>When I will run the automated_analytic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Scenario: I want to validate Hana ML PAL i...</td>\n",
              "      <td>When I will run the python code in the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Scenario: I want to validate Hana ML APL i...</td>\n",
              "      <td>Given create a pal connection\\n        ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Scenario: I want to validate python 3 Kern...</td>\n",
              "      <td>Given create an apl connection\\n       ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>#Scenario: I want to validate python 2 ker...</td>\n",
              "      <td>Given I get a python3 kernel from the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Scenario: I want to validate DATA Lake con...</td>\n",
              "      <td>#  Given I get a python2 kernel from the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Scenario: I want to validate DATA Lake con...</td>\n",
              "      <td>When I will run the DATA Lake sdl_sani...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Scenario: DI login\\n</td>\n",
              "      <td>When I will run the DATA Lake sdl_sani...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Scenario:ML Scneario Creation\\n</td>\n",
              "      <td>Given that chrome browser is open\\n     ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Scenario: User wants to create an Artifact\\n</td>\n",
              "      <td>When I navigate to ml scneario manager\\n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Scenario: User wants to retrieve an Artifact\\n</td>\n",
              "      <td>When User creates an Artifact\\n    Then Us...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Scenario: User wants to add a file to an Art...</td>\n",
              "      <td>Given User creates an Artifact\\n    When U...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Scenario: User wants to list the Artifact ob...</td>\n",
              "      <td>Given User creates an Artifact\\n    When U...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Scenario: User wants to upload a folder to a...</td>\n",
              "      <td>Given User creates an Artifact\\n    When U...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Scenario: User wants to download the content...</td>\n",
              "      <td>Given User creates an Artifact\\n    When U...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Scenario: User wants to create an Artifact w...</td>\n",
              "      <td>Given User creates an Artifact\\n    And Us...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Scenario: Training template\\n</td>\n",
              "      <td>When User creates an Artifact with local c...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Scenario: Inference template\\n</td>\n",
              "      <td>Given ML Scenario with training template\\n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>@deleteScenarioAfterwards\\n</td>\n",
              "      <td>Given ML Scenario with inference template\\...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>@deleteScenarioAfterwards\\n</td>\n",
              "      <td>Given That I have an artifact created\\n  Whe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Scenario: I want to create a python producer ...</td>\n",
              "      <td>Given That I have an artifact created\\n  Whe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Scenario: I want to create an R producer pipe...</td>\n",
              "      <td>Given I launch Scenario Manager in Data In...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>@deleteScenarioAfterwards\\n</td>\n",
              "      <td>Given I launch Scenario Manager in Data In...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Scenario: I want to Create a Scenario\\n</td>\n",
              "      <td>@critical\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Scenario: I want to delete a newly created S...</td>\n",
              "      <td>Given That I launch Scenario Manager in Da...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Scenario: User want to import tracking fro...</td>\n",
              "      <td>Given That I launch Scenario Manager in Da...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Scenario: User wants to start the run\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Scenario: User wants to log metric\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Scenario: User wants to log parameters\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Scenario: User wants to log metrics\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Scenario: User wants to set tags\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Scenario: User wants to set labels\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Scenario: User wants to end the run\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Scenario: To Fetch payload from API for th...</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Scenario: Delete all payload for the run\\n</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Scenario: User wants to run a simple trainin...</td>\n",
              "      <td>Given User selects the python 3 kernel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Scenario: User wants to run a simple trainin...</td>\n",
              "      <td>Given User creates a simple training pipel...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          requirement  ... similarity\n",
              "0       Scenario: I want to validate the functiona...  ...          1\n",
              "1       Scenario: I want to upload examples tar ba...  ...          1\n",
              "2       #Scenario: I want to validate the Python S...  ...          1\n",
              "3       Scenario: I want to validate automated pyt...  ...          1\n",
              "4       Scenario: I want to validate SSL connectiv...  ...          1\n",
              "5       Scenario: I want to validate Hana ML PAL i...  ...          1\n",
              "6       Scenario: I want to validate Hana ML APL i...  ...          1\n",
              "7       Scenario: I want to validate python 3 Kern...  ...          1\n",
              "8       #Scenario: I want to validate python 2 ker...  ...          1\n",
              "9       Scenario: I want to validate DATA Lake con...  ...          1\n",
              "10      Scenario: I want to validate DATA Lake con...  ...          1\n",
              "11                               Scenario: DI login\\n  ...          1\n",
              "12                    Scenario:ML Scneario Creation\\n  ...          1\n",
              "13       Scenario: User wants to create an Artifact\\n  ...          1\n",
              "14     Scenario: User wants to retrieve an Artifact\\n  ...          1\n",
              "15    Scenario: User wants to add a file to an Art...  ...          1\n",
              "16    Scenario: User wants to list the Artifact ob...  ...          1\n",
              "17    Scenario: User wants to upload a folder to a...  ...          1\n",
              "18    Scenario: User wants to download the content...  ...          1\n",
              "19    Scenario: User wants to create an Artifact w...  ...          1\n",
              "20                      Scenario: Training template\\n  ...          1\n",
              "21                     Scenario: Inference template\\n  ...          1\n",
              "22                        @deleteScenarioAfterwards\\n  ...          1\n",
              "23                        @deleteScenarioAfterwards\\n  ...          1\n",
              "24   Scenario: I want to create a python producer ...  ...          1\n",
              "25   Scenario: I want to create an R producer pipe...  ...          1\n",
              "26                        @deleteScenarioAfterwards\\n  ...          1\n",
              "27            Scenario: I want to Create a Scenario\\n  ...          1\n",
              "28    Scenario: I want to delete a newly created S...  ...          1\n",
              "29      Scenario: User want to import tracking fro...  ...          1\n",
              "30            Scenario: User wants to start the run\\n  ...          1\n",
              "31               Scenario: User wants to log metric\\n  ...          1\n",
              "32           Scenario: User wants to log parameters\\n  ...          1\n",
              "33              Scenario: User wants to log metrics\\n  ...          1\n",
              "34                 Scenario: User wants to set tags\\n  ...          1\n",
              "35               Scenario: User wants to set labels\\n  ...          1\n",
              "36              Scenario: User wants to end the run\\n  ...          1\n",
              "37      Scenario: To Fetch payload from API for th...  ...          1\n",
              "38         Scenario: Delete all payload for the run\\n  ...          1\n",
              "39    Scenario: User wants to run a simple trainin...  ...          1\n",
              "40    Scenario: User wants to run a simple trainin...  ...          1\n",
              "\n",
              "[41 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVDFaFT6FeKt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b50a5c77-b942-4d2f-f614-380fbfa5b499"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "  \n",
        "\n",
        "\n",
        "## filter out useless words \n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def text_to_word_list(text):\n",
        "    ''' Pre process and convert texts to a list of words '''\n",
        "    #text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMvD0-ubFeKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "efe6710b-9fd0-4720-83c6-7cf8124e17e0"
      },
      "source": [
        "# Prepare embedding\n",
        "vocabulary = dict()\n",
        "train2Dig1 = []\n",
        "# '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
        "inverse_vocabulary = ['<unk>']\n",
        "#vectors can also be instantiated from an existing file on disk in the original Google’s \n",
        "# Iterate over the questions only of both training and test datasets\n",
        "#docToVec\n",
        "\n",
        "questions_cols = ['requirement', 'testcase']\n",
        "\n",
        "# Iterate over the questions only of both training and test datasets\n",
        "for dataset in [train_df, test_df]:\n",
        "    for index, row in dataset.iterrows():\n",
        "\n",
        "        # Iterate through the text of both questions of the row\n",
        "        for question in questions_cols:\n",
        "\n",
        "            q2n = []  # q2n -> question numbers representation\n",
        "            for word in text_to_word_list(row[question]):\n",
        "\n",
        "                # Check for unwanted words\n",
        "                if word in stops and word not in word2vec.vocab:\n",
        "                    continue\n",
        "\n",
        "                if word not in vocabulary:\n",
        "                    vocabulary[word] = len(inverse_vocabulary)\n",
        "                    q2n.append(len(inverse_vocabulary))\n",
        "                    inverse_vocabulary.append(word)\n",
        "                else:\n",
        "                    q2n.append(vocabulary[word])\n",
        "\n",
        "            # Replace questions as word to question as number representation\n",
        "            dataset.set_value(index, question, q2n)\n",
        "            \n",
        "embedding_dim = 300\n",
        "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
        "embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "# Build the embedding matrix\n",
        "for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embeddings[index] = word2vec.word_vec(word)\n",
        "\n",
        "del word2vec\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9dmNGBAFeKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = max(train_df.requirement.map(lambda x: len(x)).max(),\n",
        "                     train_df.testcase.map(lambda x: len(x)).max(),\n",
        "                     test_df.requirement.map(lambda x: len(x)).max(),\n",
        "                     test_df.testcase.map(lambda x: len(x)).max())\n",
        "\n",
        "# Split to train validation\n",
        "validation_size = 400\n",
        "training_size = len(train_df) - validation_size\n",
        "\n",
        "#get data for training \n",
        "X = train_df[questions_cols]\n",
        "Y = train_df['similarity']\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\n",
        "\n",
        "\n",
        "#get data for testing \n",
        "Y_testing = test_df['similarity']\n",
        "X_testing = test_df[questions_cols]\n",
        "\n",
        "# Split to dicts\n",
        "X_train = {'left': X_train.requirement, 'right': X_train.testcase}\n",
        "X_validation = {'left': X_validation.requirement, 'right': X_validation.testcase}\n",
        "X_test = {'left': X_testing.requirement, 'right': X_testing.testcase}\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "Y_train = Y_train.values\n",
        "Y_validation = Y_validation.values\n",
        "Y_test = Y_testing.values \n",
        "\n",
        "\n",
        "\n",
        "# Zero padding\n",
        "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
        "    \n",
        "# Zero padding for testing \n",
        "for dataset, side in itertools.product([X_test], ['left', 'right']):\n",
        "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)    \n",
        "    \n",
        "\n",
        "# Make sure everything is ok\n",
        "assert X_train['left'].shape == X_train['right'].shape\n",
        "assert len(X_train['left']) == len(Y_train)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSCHt1MZFeK0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7a3a7b3-4fd8-4977-a4bc-7cee5c706aae"
      },
      "source": [
        "#Build a model \n",
        "# Model variables\n",
        "import keras\n",
        "from keras import optimizers\n",
        "n_hidden = 40\n",
        "gradient_clipping_norm = 1.25\n",
        "batch_size = 20\n",
        "n_epoch = 25\n",
        "\n",
        "def exponent_neg_manhattan_distance(left, right):\n",
        "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
        "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
        "\n",
        "# The visible layer\n",
        "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
        "\n",
        "# Embedded version of the inputs\n",
        "encoded_left = embedding_layer(left_input)\n",
        "encoded_right = embedding_layer(right_input)\n",
        "\n",
        "# Since this is a siamese network, both sides share the same LSTM\n",
        "shared_lstm = LSTM(n_hidden)\n",
        "\n",
        "left_output = shared_lstm(encoded_left)\n",
        "right_output = shared_lstm(encoded_right)\n",
        "\n",
        "# Calculates the distance as defined by the MaLSTM model\n",
        "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
        "\n",
        "# Pack it all up into a model\n",
        "malstm = Model([left_input, right_input], [malstm_distance])\n",
        "\n",
        "# Adadelta optimizer, with gradient clipping by norm\n",
        "#optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "#optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
        "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Start training\n",
        "training_start_time = time()\n",
        "\n",
        "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
        "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "#dic = dict(zip(X1test, predictions))\n",
        "#for (x,y) in dic.items():\n",
        " #   print(\"  X   :  \"     +   x   +   \"   Y  :  \"  + y)\n",
        "\n",
        "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 4046 samples, validate on 400 samples\n",
            "Epoch 1/25\n",
            "4046/4046 [==============================] - 233s 58ms/step - loss: 0.1618 - accuracy: 0.8003 - val_loss: 0.1672 - val_accuracy: 0.7700\n",
            "Epoch 2/25\n",
            "4046/4046 [==============================] - 230s 57ms/step - loss: 0.1379 - accuracy: 0.8149 - val_loss: 0.1581 - val_accuracy: 0.7775\n",
            "Epoch 3/25\n",
            "4046/4046 [==============================] - 230s 57ms/step - loss: 0.1268 - accuracy: 0.8280 - val_loss: 0.1538 - val_accuracy: 0.7850\n",
            "Epoch 4/25\n",
            "4046/4046 [==============================] - 229s 57ms/step - loss: 0.1195 - accuracy: 0.8356 - val_loss: 0.1474 - val_accuracy: 0.7950\n",
            "Epoch 5/25\n",
            "4046/4046 [==============================] - 228s 56ms/step - loss: 0.1141 - accuracy: 0.8448 - val_loss: 0.1442 - val_accuracy: 0.8050\n",
            "Epoch 6/25\n",
            "4046/4046 [==============================] - 224s 55ms/step - loss: 0.1092 - accuracy: 0.8515 - val_loss: 0.1433 - val_accuracy: 0.7975\n",
            "Epoch 7/25\n",
            "4046/4046 [==============================] - 220s 54ms/step - loss: 0.1046 - accuracy: 0.8609 - val_loss: 0.1410 - val_accuracy: 0.8000\n",
            "Epoch 8/25\n",
            "4046/4046 [==============================] - 219s 54ms/step - loss: 0.1021 - accuracy: 0.8611 - val_loss: 0.1380 - val_accuracy: 0.8125\n",
            "Epoch 9/25\n",
            "4046/4046 [==============================] - 218s 54ms/step - loss: 0.0991 - accuracy: 0.8680 - val_loss: 0.1384 - val_accuracy: 0.8150\n",
            "Epoch 10/25\n",
            "4046/4046 [==============================] - 218s 54ms/step - loss: 0.0967 - accuracy: 0.8712 - val_loss: 0.1352 - val_accuracy: 0.8125\n",
            "Epoch 11/25\n",
            "4046/4046 [==============================] - 228s 56ms/step - loss: 0.0941 - accuracy: 0.8762 - val_loss: 0.1355 - val_accuracy: 0.8125\n",
            "Epoch 12/25\n",
            "4046/4046 [==============================] - 223s 55ms/step - loss: 0.0924 - accuracy: 0.8794 - val_loss: 0.1344 - val_accuracy: 0.8175\n",
            "Epoch 13/25\n",
            "4046/4046 [==============================] - 219s 54ms/step - loss: 0.0901 - accuracy: 0.8821 - val_loss: 0.1386 - val_accuracy: 0.8125\n",
            "Epoch 14/25\n",
            "4046/4046 [==============================] - 216s 53ms/step - loss: 0.0895 - accuracy: 0.8826 - val_loss: 0.1320 - val_accuracy: 0.8150\n",
            "Epoch 15/25\n",
            "4046/4046 [==============================] - 216s 53ms/step - loss: 0.0870 - accuracy: 0.8893 - val_loss: 0.1342 - val_accuracy: 0.8200\n",
            "Epoch 16/25\n",
            "4046/4046 [==============================] - 216s 53ms/step - loss: 0.0856 - accuracy: 0.8922 - val_loss: 0.1339 - val_accuracy: 0.8225\n",
            "Epoch 17/25\n",
            "4046/4046 [==============================] - 215s 53ms/step - loss: 0.0844 - accuracy: 0.8920 - val_loss: 0.1333 - val_accuracy: 0.8175\n",
            "Epoch 18/25\n",
            "4046/4046 [==============================] - 215s 53ms/step - loss: 0.0833 - accuracy: 0.8920 - val_loss: 0.1311 - val_accuracy: 0.8200\n",
            "Epoch 19/25\n",
            "4046/4046 [==============================] - 213s 53ms/step - loss: 0.0826 - accuracy: 0.8930 - val_loss: 0.1324 - val_accuracy: 0.8225\n",
            "Epoch 20/25\n",
            "4046/4046 [==============================] - 212s 52ms/step - loss: 0.0809 - accuracy: 0.8977 - val_loss: 0.1303 - val_accuracy: 0.8225\n",
            "Epoch 21/25\n",
            "4046/4046 [==============================] - 212s 52ms/step - loss: 0.0803 - accuracy: 0.9004 - val_loss: 0.1320 - val_accuracy: 0.8175\n",
            "Epoch 22/25\n",
            "4046/4046 [==============================] - 212s 52ms/step - loss: 0.0793 - accuracy: 0.9011 - val_loss: 0.1317 - val_accuracy: 0.8250\n",
            "Epoch 23/25\n",
            "4046/4046 [==============================] - 214s 53ms/step - loss: 0.0784 - accuracy: 0.9031 - val_loss: 0.1315 - val_accuracy: 0.8225\n",
            "Epoch 24/25\n",
            "4046/4046 [==============================] - 212s 52ms/step - loss: 0.0773 - accuracy: 0.9061 - val_loss: 0.1295 - val_accuracy: 0.8325\n",
            "Epoch 25/25\n",
            "4046/4046 [==============================] - 215s 53ms/step - loss: 0.0763 - accuracy: 0.9061 - val_loss: 0.1292 - val_accuracy: 0.8300\n",
            "Training time finished.\n",
            "25 epochs in 1:31:28.367115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLcL0MxrW9qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "keras_model_path = \"/content/drive\"\n",
        "malstm.save(keras_model_path) \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiB8dAevYISV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#restored_keras_model = keras.models.load_model(keras_model_path)\n",
        "#restored_keras_model.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
        " #                           validation_data=([X_validation['left'], X_validation['right']], Y_validation))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IrWaUEfFeK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5f60644a-becb-4a32-aab0-b0cdb4abeb19"
      },
      "source": [
        "\n",
        "#get data for testing \n",
        "Y_testing = test_df['similarity']\n",
        "X_testing = test_df[questions_cols]\n",
        "#Build precision to validate the model \n",
        "pre = 0 \n",
        "precision = 0\n",
        "#convert y-test to values\n",
        "Y_test = Y_testing.values \n",
        "#split to dict \n",
        "\n",
        "for ind in range(len(X_testing)):\n",
        "       X_test = {'left': [X_testing.iloc[ind].requirement for i in range(len(X_testing))], 'right': X_testing.testcase}\n",
        "       #make the testing        \n",
        "# Zero padding for testing \n",
        "       for dataset, side in itertools.product([X_test], ['left', 'right']):\n",
        "             dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length) \n",
        "       \n",
        "       predictions = malstm.predict([X_test['left'],X_test['right']],verbose=0,batch_size = 10)\n",
        "       predicting = []\n",
        "       list = predictions.tolist()\n",
        "       for x in list:\n",
        "             predicting.extend(x)\n",
        "             #print(\"Prediction Probability\",predicting)    \n",
        "       order_list = sorted(predicting)\n",
        "       #print(\"Prediction Probability\",order_list)    \n",
        "       for x in (order_list[:15]):\n",
        "            index = predicting.index(x)\n",
        "            if index == ind:\n",
        "                #print(\"SUCCES : \",test[index])\n",
        "                    print(\"ind : \",ind) \n",
        "                    print(\"index : \",index)\n",
        "                    print(\"test \",test[index])\n",
        "                    pre +=1\n",
        "                    print(\"Pre : \",pre)\n",
        "                           \n",
        "print(\"precision :\",round(pre/len(X_testing) * 100,2),'%.')  \n",
        "for k, v in X_test.items():\n",
        "    print(k, v) \n",
        "           \n",
        "\n",
        " \n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ind :  6\n",
            "index :  6\n",
            "test         Given create a pal connection\n",
            "        When I will run the hana_PAL_regressor notebook\n",
            "        Then I will validate the hana_pal_regressor notebook executed properly\n",
            "\n",
            "Pre :  1\n",
            "ind :  8\n",
            "index :  8\n",
            "test          Given I get a python3 kernel from the current scenario\n",
            "        When I will run the import library code in python3 kernel\n",
            "        Then I will verify all the libraries get imported in python3\n",
            "\n",
            "Pre :  2\n",
            "ind :  9\n",
            "index :  9\n",
            "test        #  Given I get a python2 kernel from the current scenario\n",
            "      #  When I will run the import library code in python2 kernel\n",
            "      # Then I will verify all the libraries get imported in python2\n",
            "\n",
            "\n",
            "Pre :  3\n",
            "ind :  22\n",
            "index :  22\n",
            "test      Given ML Scenario with inference template\n",
            "    When this inference pipeline is executed\n",
            "    Then model is successfully served\n",
            "Feature:   Inference pipeline validation with the model generated by artifact producer pipeline\n",
            "\n",
            "\n",
            " @createAndValidateArtifactProducerPipelineBeforehand\n",
            "\n",
            "Pre :  4\n",
            "ind :  23\n",
            "index :  23\n",
            "test    Given That I have an artifact created\n",
            "  When I create a Inference pipeline with the name some_name and some_template\n",
            "  And I validate pipeline creation is successful\n",
            "  And I create a new scenario version\n",
            "  And I create the configurations for the pipeline\n",
            "  And I deploy the pipeline\n",
            "  Then I ensure status is RUNNING\n",
            "  When I run the inference with some_model_name, input_data\n",
            "  Then I ensure inference request is as expected\n",
            "Feature:   Inference pipeline validation with the model generated by training pipeline\n",
            "\n",
            "\n",
            " @createAndValidateTrainingPipelineBeforehand\n",
            "\n",
            "Pre :  5\n",
            "ind :  29\n",
            "index :  29\n",
            "test      Given That I launch Scenario Manager in Data Intelligence Launch Pad\n",
            "    And I create a new Scenario Manager with sm_name and sm_business_question\n",
            "    When I delete my newly Scenario Manager with sm_name and sm_business_question\n",
            "    Then I ensure my scenario is deleted\n",
            "@create_scenario\n",
            "@delete_scenario\n",
            "Feature: import tracking and log metrics\n",
            "    Feature Description: User starts his experiment persisting metrics during Start run\n",
            "    @critical\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  6\n",
            "ind :  30\n",
            "index :  30\n",
            "test          Given User selects the python 3 kernel\n",
            "        When User imports tracking from sapdi\n",
            "        Then User should be able to do it without error\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  7\n",
            "ind :  31\n",
            "index :  31\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        When User starts the run of a experiment\n",
            "        Then User should be able to see the run_id\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  8\n",
            "ind :  32\n",
            "index :  32\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        And User starts the run of a experiment\n",
            "        When User logs a metric\n",
            "        Then User should be able to do it without error\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  9\n",
            "ind :  33\n",
            "index :  33\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        And User starts the run of a experiment\n",
            "        When User log parameters\n",
            "        Then User should be able to do it without error\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  10\n",
            "ind :  34\n",
            "index :  34\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        And User starts the run of a experiment\n",
            "        When User logs metrics\n",
            "        Then User should be able to do it without error\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  11\n",
            "ind :  35\n",
            "index :  35\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        And User starts the run of a experiment\n",
            "        When User set tags\n",
            "        Then User should be able to do it without error\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  12\n",
            "ind :  36\n",
            "index :  36\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        And User starts the run of a experiment\n",
            "        When User set labels\n",
            "        Then User should be able to do it without error\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  13\n",
            "ind :  37\n",
            "index :  37\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        And User starts the run of a experiment\n",
            "        And User logs a metric\n",
            "        When User ends the run\n",
            "        Then User should be able to do it without error\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  14\n",
            "ind :  38\n",
            "index :  38\n",
            "test          Given User selects the python 3 kernel\n",
            "        And User imports tracking from sapdi\n",
            "        And User starts the run of a experiment\n",
            "        And User logs a metric\n",
            "        And User set tags\n",
            "        And User set labels\n",
            "        And User ends the run\n",
            "        When User tries to get payload\n",
            "        Then User should be able to see the metrics posted\n",
            "\n",
            "    @createNotebookBeforehand\n",
            "\n",
            "Pre :  15\n",
            "precision : 36.59 %.\n",
            "left [[   0    0    0 ...    5  195 1807]\n",
            " [   0    0    0 ...    5  195 1807]\n",
            " [   0    0    0 ...    5  195 1807]\n",
            " ...\n",
            " [   0    0    0 ...    5  195 1807]\n",
            " [   0    0    0 ...    5  195 1807]\n",
            " [   0    0    0 ...    5  195 1807]]\n",
            "right [[   0    0    0 ...   54   36   56]\n",
            " [   0    0    0 ...  549 1758 1761]\n",
            " [   0    0    0 ...   67 1497 1764]\n",
            " ...\n",
            " [   0    0    0 ... 1850 1871 1863]\n",
            " [   0    0    0 ... 1835 1293   51]\n",
            " [   0    0    0 ...  660  147 1417]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhFWoRAdFeLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}