{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "FIRST_TXT = 'TRAIN1.txt'\n",
    "SECOND_TXT = 'TEST.txt'\n",
    "THIRD_TXT = 'TRAIN2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req length 3944\n",
      "test len  3944\n",
      "sim length  3944\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requirement</th>\n",
       "      <th>testcase</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Scenario: Feature Setup\\n</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Scenario: Feature with a Background and Scen...</td>\n",
       "      <td>Given a new working directory\\n    And a f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Scenario: S1\\n</td>\n",
       "      <td>Given a file named \"features/background_ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Scenario: S2\\n</td>\n",
       "      <td>When a step passes\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Scenario: S1\\n</td>\n",
       "      <td>Then a step passes\\n            An...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3939</td>\n",
       "      <td>Scenario Outline: Named Examples -- @1.2...</td>\n",
       "      <td>Given a step passes\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>Scenario: Disable name annotations (use: old...</td>\n",
       "      <td>Given the following user-data is p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3941</td>\n",
       "      <td>Scenario: 3\\n</td>\n",
       "      <td>When a step passes\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3942</td>\n",
       "      <td>Scenario: Ensure environment assumptions are...</td>\n",
       "      <td>Given the following user-data is p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3943</td>\n",
       "      <td>Scenario: Ensure --version option is process...</td>\n",
       "      <td>Given the following user-data is p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3944 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            requirement  \\\n",
       "0                             Scenario: Feature Setup\\n   \n",
       "1       Scenario: Feature with a Background and Scen...   \n",
       "2                                        Scenario: S1\\n   \n",
       "3                                        Scenario: S2\\n   \n",
       "4                                        Scenario: S1\\n   \n",
       "...                                                 ...   \n",
       "3939        Scenario Outline: Named Examples -- @1.2...   \n",
       "3940    Scenario: Disable name annotations (use: old...   \n",
       "3941                                      Scenario: 3\\n   \n",
       "3942    Scenario: Ensure environment assumptions are...   \n",
       "3943    Scenario: Ensure --version option is process...   \n",
       "\n",
       "                                               testcase similarity  \n",
       "0                                                                1  \n",
       "1         Given a new working directory\\n    And a f...          1  \n",
       "2         Given a file named \"features/background_ex...          1  \n",
       "3                                  When a step passes\\n          1  \n",
       "4                 Then a step passes\\n            An...          1  \n",
       "...                                                 ...        ...  \n",
       "3939                              Given a step passes\\n          0  \n",
       "3940              Given the following user-data is p...          0  \n",
       "3941                               When a step passes\\n          0  \n",
       "3942              Given the following user-data is p...          1  \n",
       "3943              Given the following user-data is p...          1  \n",
       "\n",
       "[3944 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "help = []\n",
    "req = []\n",
    "test = []\n",
    "sim = []\n",
    "scenario = False\n",
    "te = True\n",
    "#writing from file one to file two \n",
    "c = 0 \n",
    "with open(FIRST_TXT, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "            #print('\\n',\"WHen THEN \",line)\n",
    "            if(\"Scenario\" not in line[:20] and scenario):\n",
    "                 help.append(line) \n",
    "                 te = True   \n",
    "            elif  \"Scenario\" in  line[:20] and te:\n",
    "                 #print(\"Help \",help)\n",
    "                 test.append(''.join(help))\n",
    "                 #print('\\n',\"Scenario \",line)\n",
    "                 req.append(line)\n",
    "                 scenario = True\n",
    "                 help = []\n",
    "                 sim.append(\"1\")\n",
    "                 te = False   \n",
    "for i in range(3000):\n",
    "    s1 = random.choice(req)\n",
    "    s2 = random.choice(test)\n",
    "    ind1 = req.index(s1)\n",
    "    ind2 = test.index(s2)\n",
    "    if ind1 != ind2:\n",
    "        req.append(s1)\n",
    "        test.append(s2)\n",
    "        sim.append(\"0\")\n",
    "        \n",
    "# Optional : trying to add data from another repository\n",
    "with open(THIRD_TXT, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "            #print('\\n',\"WHen THEN \",line)\n",
    "            if(\"Scenario\" not in line[:20] and scenario):\n",
    "                 help.append(line) \n",
    "                 te = True   \n",
    "            elif  \"Scenario\" in  line[:20] and te:\n",
    "                 #print(\"Help \",help)\n",
    "                 test.append(''.join(help))\n",
    "                 #print('\\n',\"Scenario \",line)\n",
    "                 req.append(line)\n",
    "                 scenario = True\n",
    "                 sim.append(\"1\")\n",
    "                 te = False  \n",
    "# the end of optional adding         \n",
    "        \n",
    "print(\"req length\",len(req))\n",
    "print(\"test len \" , len(test))\n",
    "print(\"sim length \", len(sim))\n",
    "\n",
    "df = {'requirement':req , 'testcase': test,'similarity': sim}  \n",
    "train_df = pd.DataFrame(df) \n",
    "train_df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "req length 41\n",
      "test len  41\n",
      "sim length  41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>requirement</th>\n",
       "      <th>testcase</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Scenario: I want to validate the functiona...</td>\n",
       "      <td>Given the following user-data is p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Scenario: I want to upload examples tar ba...</td>\n",
       "      <td>When I create a new JL notebook with n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>#Scenario: I want to validate the Python S...</td>\n",
       "      <td>When I upload the example tar ball fil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Scenario: I want to validate automated pyt...</td>\n",
       "      <td># Given I will get a kernel existing in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Scenario: I want to validate SSL connectiv...</td>\n",
       "      <td>When I will run the automated_analytic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Scenario: I want to validate Hana ML PAL i...</td>\n",
       "      <td>When I will run the python code in the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Scenario: I want to validate Hana ML APL i...</td>\n",
       "      <td>Given create a pal connection\\n        ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Scenario: I want to validate python 3 Kern...</td>\n",
       "      <td>Given create an apl connection\\n       ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>#Scenario: I want to validate python 2 ker...</td>\n",
       "      <td>Given I get a python3 kernel from the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Scenario: I want to validate DATA Lake con...</td>\n",
       "      <td>#  Given I get a python2 kernel from the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Scenario: I want to validate DATA Lake con...</td>\n",
       "      <td>When I will run the DATA Lake sdl_sani...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Scenario: DI login\\n</td>\n",
       "      <td>When I will run the DATA Lake sdl_sani...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Scenario:ML Scneario Creation\\n</td>\n",
       "      <td>Given that chrome browser is open\\n     ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Scenario: User wants to create an Artifact\\n</td>\n",
       "      <td>When I navigate to ml scneario manager\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Scenario: User wants to retrieve an Artifact\\n</td>\n",
       "      <td>When User creates an Artifact\\n    Then Us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Scenario: User wants to add a file to an Art...</td>\n",
       "      <td>Given User creates an Artifact\\n    When U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Scenario: User wants to list the Artifact ob...</td>\n",
       "      <td>Given User creates an Artifact\\n    When U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Scenario: User wants to upload a folder to a...</td>\n",
       "      <td>Given User creates an Artifact\\n    When U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Scenario: User wants to download the content...</td>\n",
       "      <td>Given User creates an Artifact\\n    When U...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Scenario: User wants to create an Artifact w...</td>\n",
       "      <td>Given User creates an Artifact\\n    And Us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Scenario: Training template\\n</td>\n",
       "      <td>When User creates an Artifact with local c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Scenario: Inference template\\n</td>\n",
       "      <td>Given ML Scenario with training template\\n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>@deleteScenarioAfterwards\\n</td>\n",
       "      <td>Given ML Scenario with inference template\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>@deleteScenarioAfterwards\\n</td>\n",
       "      <td>Given That I have an artifact created\\n  Whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>Scenario: I want to create a python producer ...</td>\n",
       "      <td>Given That I have an artifact created\\n  Whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>Scenario: I want to create an R producer pipe...</td>\n",
       "      <td>Given I launch Scenario Manager in Data In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>@deleteScenarioAfterwards\\n</td>\n",
       "      <td>Given I launch Scenario Manager in Data In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>Scenario: I want to Create a Scenario\\n</td>\n",
       "      <td>@critical\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>Scenario: I want to delete a newly created S...</td>\n",
       "      <td>Given That I launch Scenario Manager in Da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Scenario: User want to import tracking fro...</td>\n",
       "      <td>Given That I launch Scenario Manager in Da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>Scenario: User wants to start the run\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>Scenario: User wants to log metric\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>Scenario: User wants to log parameters\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Scenario: User wants to log metrics\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>Scenario: User wants to set tags\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>Scenario: User wants to set labels\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>Scenario: User wants to end the run\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>Scenario: To Fetch payload from API for th...</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>Scenario: Delete all payload for the run\\n</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>Scenario: User wants to run a simple trainin...</td>\n",
       "      <td>Given User selects the python 3 kernel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>Scenario: User wants to run a simple trainin...</td>\n",
       "      <td>Given User creates a simple training pipel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          requirement  \\\n",
       "0       Scenario: I want to validate the functiona...   \n",
       "1       Scenario: I want to upload examples tar ba...   \n",
       "2       #Scenario: I want to validate the Python S...   \n",
       "3       Scenario: I want to validate automated pyt...   \n",
       "4       Scenario: I want to validate SSL connectiv...   \n",
       "5       Scenario: I want to validate Hana ML PAL i...   \n",
       "6       Scenario: I want to validate Hana ML APL i...   \n",
       "7       Scenario: I want to validate python 3 Kern...   \n",
       "8       #Scenario: I want to validate python 2 ker...   \n",
       "9       Scenario: I want to validate DATA Lake con...   \n",
       "10      Scenario: I want to validate DATA Lake con...   \n",
       "11                               Scenario: DI login\\n   \n",
       "12                    Scenario:ML Scneario Creation\\n   \n",
       "13       Scenario: User wants to create an Artifact\\n   \n",
       "14     Scenario: User wants to retrieve an Artifact\\n   \n",
       "15    Scenario: User wants to add a file to an Art...   \n",
       "16    Scenario: User wants to list the Artifact ob...   \n",
       "17    Scenario: User wants to upload a folder to a...   \n",
       "18    Scenario: User wants to download the content...   \n",
       "19    Scenario: User wants to create an Artifact w...   \n",
       "20                      Scenario: Training template\\n   \n",
       "21                     Scenario: Inference template\\n   \n",
       "22                        @deleteScenarioAfterwards\\n   \n",
       "23                        @deleteScenarioAfterwards\\n   \n",
       "24   Scenario: I want to create a python producer ...   \n",
       "25   Scenario: I want to create an R producer pipe...   \n",
       "26                        @deleteScenarioAfterwards\\n   \n",
       "27            Scenario: I want to Create a Scenario\\n   \n",
       "28    Scenario: I want to delete a newly created S...   \n",
       "29      Scenario: User want to import tracking fro...   \n",
       "30            Scenario: User wants to start the run\\n   \n",
       "31               Scenario: User wants to log metric\\n   \n",
       "32           Scenario: User wants to log parameters\\n   \n",
       "33              Scenario: User wants to log metrics\\n   \n",
       "34                 Scenario: User wants to set tags\\n   \n",
       "35               Scenario: User wants to set labels\\n   \n",
       "36              Scenario: User wants to end the run\\n   \n",
       "37      Scenario: To Fetch payload from API for th...   \n",
       "38         Scenario: Delete all payload for the run\\n   \n",
       "39    Scenario: User wants to run a simple trainin...   \n",
       "40    Scenario: User wants to run a simple trainin...   \n",
       "\n",
       "                                             testcase similarity  \n",
       "0               Given the following user-data is p...          1  \n",
       "1           When I create a new JL notebook with n...          1  \n",
       "2           When I upload the example tar ball fil...          1  \n",
       "3          # Given I will get a kernel existing in...          1  \n",
       "4           When I will run the automated_analytic...          1  \n",
       "5           When I will run the python code in the...          1  \n",
       "6          Given create a pal connection\\n        ...          1  \n",
       "7          Given create an apl connection\\n       ...          1  \n",
       "8           Given I get a python3 kernel from the ...          1  \n",
       "9         #  Given I get a python2 kernel from the...          1  \n",
       "10          When I will run the DATA Lake sdl_sani...          1  \n",
       "11          When I will run the DATA Lake sdl_sani...          1  \n",
       "12        Given that chrome browser is open\\n     ...          1  \n",
       "13        When I navigate to ml scneario manager\\n...          1  \n",
       "14      When User creates an Artifact\\n    Then Us...          1  \n",
       "15      Given User creates an Artifact\\n    When U...          1  \n",
       "16      Given User creates an Artifact\\n    When U...          1  \n",
       "17      Given User creates an Artifact\\n    When U...          1  \n",
       "18      Given User creates an Artifact\\n    When U...          1  \n",
       "19      Given User creates an Artifact\\n    And Us...          1  \n",
       "20      When User creates an Artifact with local c...          1  \n",
       "21      Given ML Scenario with training template\\n...          1  \n",
       "22      Given ML Scenario with inference template\\...          1  \n",
       "23    Given That I have an artifact created\\n  Whe...          1  \n",
       "24    Given That I have an artifact created\\n  Whe...          1  \n",
       "25      Given I launch Scenario Manager in Data In...          1  \n",
       "26      Given I launch Scenario Manager in Data In...          1  \n",
       "27                                        @critical\\n          1  \n",
       "28      Given That I launch Scenario Manager in Da...          1  \n",
       "29      Given That I launch Scenario Manager in Da...          1  \n",
       "30          Given User selects the python 3 kernel...          1  \n",
       "31          Given User selects the python 3 kernel...          1  \n",
       "32          Given User selects the python 3 kernel...          1  \n",
       "33          Given User selects the python 3 kernel...          1  \n",
       "34          Given User selects the python 3 kernel...          1  \n",
       "35          Given User selects the python 3 kernel...          1  \n",
       "36          Given User selects the python 3 kernel...          1  \n",
       "37          Given User selects the python 3 kernel...          1  \n",
       "38          Given User selects the python 3 kernel...          1  \n",
       "39          Given User selects the python 3 kernel...          1  \n",
       "40      Given User creates a simple training pipel...          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "req = []\n",
    "test = []\n",
    "sim = []\n",
    "scenario = False\n",
    "te = True\n",
    "#writing from file one to file two \n",
    "c = 0 \n",
    "with open(SECOND_TXT, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "for line in lines:\n",
    "            #print('\\n',\"WHen THEN \",line)\n",
    "            if(\"Scenario\" not in line[:20] and scenario):\n",
    "                 help.append(line) \n",
    "                 te = True   \n",
    "            elif  \"Scenario\" in  line[:20] and te:\n",
    "                 #print(\"Help \",help)\n",
    "                 test.append(''.join(help))\n",
    "                 #print('\\n',\"Scenario \",line)\n",
    "                 req.append(line)\n",
    "                 scenario = True\n",
    "                 help = []\n",
    "                 sim.append(\"1\")\n",
    "                 te = False \n",
    "'''\n",
    "for i in range(30):\n",
    "    s1 = random.choice(req)\n",
    "    s2 = random.choice(test)\n",
    "    ind1 = req.index(s1)\n",
    "    ind2 = test.index(s2)\n",
    "    if ind1 != ind2:\n",
    "        req.append(s1)\n",
    "        test.append(s2)\n",
    "        sim.append(\"0\")\n",
    "'''                        \n",
    "print(\"req length\",len(req))\n",
    "print(\"test len \" , len(test))\n",
    "print(\"sim length \", len(sim))\n",
    "\n",
    "df = {'requirement':req , 'testcase': test,'similarity': sim}  \n",
    "test_df = pd.DataFrame(df) \n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/i522408/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "  \n",
    "\n",
    "\n",
    "## filter out useless words \n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    #text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i522408/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "# Prepare embedding\n",
    "vocabulary = dict()\n",
    "train2Dig1 = []\n",
    "# '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
    "inverse_vocabulary = ['<unk>']\n",
    "#vectors can also be instantiated from an existing file on disk in the original Google’s \n",
    "# Iterate over the questions only of both training and test datasets\n",
    "#docToVec\n",
    "\n",
    "questions_cols = ['requirement', 'testcase']\n",
    "\n",
    "# Iterate over the questions only of both training and test datasets\n",
    "for dataset in [train_df, test_df]:\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in questions_cols:\n",
    "\n",
    "            q2n = []  # q2n -> question numbers representation\n",
    "            for word in text_to_word_list(row[question]):\n",
    "\n",
    "                # Check for unwanted words\n",
    "                if word in stops and word not in word2vec.vocab:\n",
    "                    continue\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    q2n.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    q2n.append(vocabulary[word])\n",
    "\n",
    "            # Replace questions as word to question as number representation\n",
    "            dataset.set_value(index, question, q2n)\n",
    "            \n",
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)\n",
    "\n",
    "del word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = max(train_df.requirement.map(lambda x: len(x)).max(),\n",
    "                     train_df.testcase.map(lambda x: len(x)).max(),\n",
    "                     test_df.requirement.map(lambda x: len(x)).max(),\n",
    "                     test_df.testcase.map(lambda x: len(x)).max())\n",
    "\n",
    "# Split to train validation\n",
    "validation_size = 70\n",
    "training_size = len(train_df) - validation_size\n",
    "\n",
    "#get data for training \n",
    "X = train_df[questions_cols]\n",
    "Y = train_df['similarity']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=validation_size)\n",
    "\n",
    "\n",
    "#get data for testing \n",
    "Y_testing = test_df['similarity']\n",
    "X_testing = test_df[questions_cols]\n",
    "\n",
    "# Split to dicts\n",
    "X_train = {'left': X_train.requirement, 'right': X_train.testcase}\n",
    "X_validation = {'left': X_validation.requirement, 'right': X_validation.testcase}\n",
    "X_test = {'left': X_testing.requirement, 'right': X_testing.testcase}\n",
    "\n",
    "# Convert labels to their numpy representations\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values\n",
    "Y_test = Y_testing.values \n",
    "\n",
    "\n",
    "\n",
    "# Zero padding\n",
    "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
    "    \n",
    "# Zero padding for testing \n",
    "for dataset, side in itertools.product([X_test], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)    \n",
    "    \n",
    "\n",
    "# Make sure everything is ok\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i522408/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3874 samples, validate on 70 samples\n",
      "Epoch 1/13\n",
      "3874/3874 [==============================] - 80s 21ms/step - loss: 0.1884 - accuracy: 0.7648 - val_loss: 0.1334 - val_accuracy: 0.8429\n",
      "Epoch 2/13\n",
      "3874/3874 [==============================] - 75s 19ms/step - loss: 0.1625 - accuracy: 0.7783 - val_loss: 0.1332 - val_accuracy: 0.8286\n",
      "Epoch 3/13\n",
      "3874/3874 [==============================] - 75s 19ms/step - loss: 0.1487 - accuracy: 0.7989 - val_loss: 0.1260 - val_accuracy: 0.8286\n",
      "Epoch 4/13\n",
      "3874/3874 [==============================] - 83s 21ms/step - loss: 0.1404 - accuracy: 0.8064 - val_loss: 0.1262 - val_accuracy: 0.8286\n",
      "Epoch 5/13\n",
      "3874/3874 [==============================] - 82s 21ms/step - loss: 0.1330 - accuracy: 0.8147 - val_loss: 0.1286 - val_accuracy: 0.8143\n",
      "Epoch 6/13\n",
      "3874/3874 [==============================] - 80s 21ms/step - loss: 0.1279 - accuracy: 0.8206 - val_loss: 0.1320 - val_accuracy: 0.8143\n",
      "Epoch 7/13\n",
      "3874/3874 [==============================] - 83s 21ms/step - loss: 0.1239 - accuracy: 0.8299 - val_loss: 0.1233 - val_accuracy: 0.8143\n",
      "Epoch 8/13\n",
      "3874/3874 [==============================] - 78s 20ms/step - loss: 0.1201 - accuracy: 0.8338 - val_loss: 0.1226 - val_accuracy: 0.8143\n",
      "Epoch 9/13\n",
      "3874/3874 [==============================] - 82s 21ms/step - loss: 0.1175 - accuracy: 0.8407 - val_loss: 0.1292 - val_accuracy: 0.8143\n",
      "Epoch 10/13\n",
      "3874/3874 [==============================] - 79s 20ms/step - loss: 0.1137 - accuracy: 0.8480 - val_loss: 0.1269 - val_accuracy: 0.8143\n",
      "Epoch 11/13\n",
      "3874/3874 [==============================] - 80s 21ms/step - loss: 0.1111 - accuracy: 0.8472 - val_loss: 0.1300 - val_accuracy: 0.8143\n",
      "Epoch 12/13\n",
      "3874/3874 [==============================] - 86s 22ms/step - loss: 0.1085 - accuracy: 0.8531 - val_loss: 0.1326 - val_accuracy: 0.8143\n",
      "Epoch 13/13\n",
      "3874/3874 [==============================] - 92s 24ms/step - loss: 0.1061 - accuracy: 0.8573 - val_loss: 0.1216 - val_accuracy: 0.8143\n",
      "Training time finished.\n",
      "13 epochs in 0:17:36.622236\n"
     ]
    }
   ],
   "source": [
    "#Build a model \n",
    "# Model variables\n",
    "import keras\n",
    "from keras import optimizers\n",
    "n_hidden = 40\n",
    "gradient_clipping_norm = 1.25\n",
    "batch_size = 50\n",
    "n_epoch = 13\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "\n",
    "# Adadelta optimizer, with gradient clipping by norm\n",
    "#optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "#optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n",
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Start training\n",
    "training_start_time = time()\n",
    "\n",
    "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, nb_epoch=n_epoch,\n",
    "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#dic = dict(zip(X1test, predictions))\n",
    "#for (x,y) in dic.items():\n",
    " #   print(\"  X   :  \"     +   x   +   \"   Y  :  \"  + y)\n",
    "\n",
    "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Probability [0.69626384973526, 0.6466935276985168, 0.5042315125465393, 0.4683612585067749, 0.3911798894405365, 0.36611175537109375, 0.35609644651412964, 0.3271333873271942, 0.3257259726524353, 0.3075990378856659, 0.27390116453170776, 0.2702676057815552, 0.2642936706542969, 0.259101003408432, 0.25117433071136475, 0.2311737835407257, 0.23112991452217102, 0.22501930594444275, 0.20490920543670654, 0.19660769402980804, 0.14725446701049805, 0.13761883974075317, 0.12191110849380493, 0.10829566419124603, 0.08021581172943115, 0.0637984573841095, 0.0485801175236702, 0.034782152622938156, 0.017033372074365616, 0.011213880032300949, 0.0031878172885626554, 0.00022556674957741052, 0.00017688026127871126, 0.0001766525092534721, 0.00014492773334495723, 0.00014076419756747782, 0.00013289831986185163, 0.00012890802463516593, 0.00012791607878170907, 0.00011867152352351695, 4.7764206101419404e-05]\n",
      "\n",
      "\n",
      "Requirement priorities\n",
      "\n",
      "\n",
      "1  Scenario: I want to delete a newly created Scenario\n",
      "\n",
      "2  Scenario: User wants to retrieve an Artifact\n",
      "\n",
      "3  Scenario: User wants to add a file to an Artifact\n",
      "\n",
      "4  Scenario: User wants to upload a folder to an Artifact\n",
      "\n",
      "5  Scenario: User wants to create an Artifact with local content\n",
      "\n",
      "6    Scenario: I want to validate python 3 Kernel\n",
      "\n",
      "7  Scenario: User wants to run a simple training pipeline with an artifact\n",
      "\n",
      "8  Scenario: User wants to list the Artifact objects registered in the scenario\n",
      "\n",
      "9    Scenario: I want to validate Hana ML PAL installation\n",
      "\n",
      "10  Scenario: User wants to run a simple training pipeline\n",
      "\n",
      "11  Scenario: Inference template\n",
      "\n",
      "12  Scenario: User wants to download the content of an Artifact\n",
      "\n",
      "13  Scenario: Training template\n",
      "\n",
      "14  Scenario: I want to Create a Scenario\n",
      "\n",
      "15  Scenario: User wants to create an Artifact\n",
      "\n",
      "16   Scenario: DI login\n",
      "\n",
      "17    Scenario: I want to validate the functional correctness of Jupyter Lab and its notebooks\n",
      "\n",
      "18    Scenario: I want to validate DATA Lake connectivity with Sdl(WORM) Installation\n",
      "\n",
      "19    #Scenario: I want to validate the Python SDK Installation\n",
      "\n",
      "20 Scenario: I want to create an R producer pipeline and an R consumer pipeline\n",
      "\n",
      "21  @deleteScenarioAfterwards\n",
      "\n",
      "22 Scenario: I want to create a python producer pipeline and a python consumer pipeline\n",
      "\n",
      "23    Scenario: I want to validate Hana ML APL installation\n",
      "\n",
      "24    Scenario: I want to upload examples tar ball file and extract\n",
      "\n",
      "25   Scenario:ML Scneario Creation\n",
      "\n",
      "26    Scenario: I want to validate SSL connectivity to Hana from Jupyter Lab\n",
      "\n",
      "27 @deleteScenarioAfterwards\n",
      "\n",
      "28    Scenario: I want to validate automated python library InstallationI will run the hana_PAL_regressor notebook\n",
      "\n",
      "29    #Scenario: I want to validate python 2 kernel\n",
      "\n",
      "30    Scenario: I want to validate DATA Lake connectivity with Sdl(SHARED) Installation\n",
      "\n",
      "31 @deleteScenarioAfterwards\n",
      "\n",
      "32    Scenario: User wants to log metric\n",
      "\n",
      "33    Scenario: User wants to set labels\n",
      "\n",
      "34    Scenario: Delete all payload for the run\n",
      "\n",
      "35    Scenario: User wants to log metrics\n",
      "\n",
      "36    Scenario: User wants to log parameters\n",
      "\n",
      "37    Scenario: User wants to start the run\n",
      "\n",
      "38    Scenario: User wants to end the run\n",
      "\n",
      "39    Scenario: To Fetch payload from API for the current run\n",
      "\n",
      "40    Scenario: User wants to set tags\n",
      "\n",
      "41    Scenario: User want to import tracking from sapdi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make the testing \n",
    "predictions = malstm.predict([X_test['left'],X_test['right']],verbose=0,batch_size = 10)\n",
    "#pred = np.around(predictions)\n",
    "predicting = []\n",
    "list = predictions.tolist()\n",
    "for x in list:\n",
    "    predicting.extend(x)\n",
    "#print(\"Prediction Probability\",predicting)    \n",
    "order_list = sorted(predicting, reverse = True)\n",
    "print(\"Prediction Probability\",order_list)    \n",
    "print('\\n')\n",
    "#dictionary contains the requirement orderred regarding \n",
    "print(\"Requirement priorities\")\n",
    "print('\\n')\n",
    "for i,x in enumerate(order_list):\n",
    "    index = predicting.index(x)\n",
    "    print('{}{}'.format(i+1,req[index]))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "p = []\n",
    "pred = np.around(predictions)\n",
    "for x in pred:\n",
    "    p.extend(x)\n",
    "p = [int(x) for x in p]    \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
